services:
  image-only: # Base service to build the image.
    image: ${LAB_NAME}/<project-name>:${USR}
    platform: "linux/amd64"
    build:
      platforms:
        - "linux/amd64"
      target: train
      args:
        PROJECT_NAME: <project-name>
        BASE_IMAGE: ubuntu:22.04                # Ubuntu: https://hub.docker.com/_/ubuntu
        CURL_IMAGE: curlimages/curl:8.00.1      # https://hub.docker.com/r/curlimages/curl/tags
        GIT_IMAGE: alpine/git:edge-2.38.1       # https://hub.docker.com/r/alpine/git/tags
        CONDA_URL:
          https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh
           # https://github.com/conda-forge/miniforge/releases/
        CONDA_MANAGER: mamba
        GID: ${GID}
        UID: ${UID}
        GRP: ${GRP}
        USR: ${USR}
        PASSWD: ${PASSWD}
        PROJECT_ROOT: /opt/project
        CODE_DIR: /opt/project/code
        DATA_DIR: /opt/project/data
        LOGS_DIR: /opt/project/logs

  local-cpu:   # Service to run the image locally with CPU only.
    extends:
        service: image-only
    tty: true
    stdin_open: true
    volumes:
      - ${LOCAL_CODE_DIR}:/opt/project/code
      - ${LOCAL_DATA_DIR}:/opt/project/data
      - ${LOCAL_LOGS_DIR}:/opt/project/logs
    environment:
      WANDB_API_KEY: ${WANDB_API_KEY}

  local-gpu:   # Service to run the image locally with NVIDIA GPU.
    extends:
      service: local-cpu
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]

